\documentclass[ % ドキュメントクラス
  uplatex,%upLaTeXを使う
  papersize%紙のサイズがデフォルトと違う場合、PDFにうまく伝える
]{jsarticle}

%% フォント関連
\usepackage{authblk}
\usepackage{diagbox}
\usepackage{bm}
\usepackage[T1]{fontenc} % フォントでT1を使うこと
\usepackage{textcomp} % フォントでTS1を使うこと
\usepackage[utf8]{inputenc} % ファイルがUTF8であること
\usepackage{newpxtext,newpxmath} % ローマンと数式の字体をPalatinoに基づいた新PXフォントで
\usepackage{zi4}%等幅フォントをInconsolataで
\usepackage[multi,deluxe,jis2004]{otf}
\usepackage[prefernoncjk]{pxcjkcat} % なるべく「半角」扱いで。
\cjkcategory{sym18}{cjk} % sym18 (U+25A0 - U+25FF Geometric Shapes) を和文文字あつかい

%% 図表など
% 図の読みこみのために
\usepackage[dvipdfmx, hiresbb]{graphicx, xcolor}

\usepackage{multirow}
\usepackage{multicol}

\usepackage{booktabs} % 表の横罫線
\usepackage{lscape}  % 表などを90度回転させる

%% 囲み枠
\usepackage{tcolorbox}
\tcbuselibrary{breakable} % ページをまたいで分割できるように

% ソースコードをきれいに出力する
\usepackage{listings}
\lstset{ % 色々な設定
    basicstyle=\ttfamily\scriptsize, % 基本的にタイプライター体にする
    %numbers=left, % 左側に行番号を表示
    %numberstyle=\small, % 行番号は小さめに
    %numbersep=16pt, % 行番号をどれだけ離すか
    % showspaces=true,% スペースを表示したければtrueにする 
    xleftmargin=15pt, % 左側のマージン
    frame=single, %ソースコードを囲むフレーム
    framesep=10pt, %フレームとコードの間隔
    backgroundcolor=\color[gray]{0.95}, % 背景色
    breaklines=true, % 長い行は改行する
    commentstyle=\color{red},
    keywordstyle=\color{blue}
}
\renewcommand{\lstlistingname}{ソースコード}

% misc
\usepackage{okumacro} % 圏点などのため
\usepackage{pxrubrica} % ルビをつける（okumacroのrubyは使わない）

% hyperrefの設定
\usepackage[dvipdfmx,%
   bookmarks=true,%PDFにしおりをつける
   bookmarksnumbered=true,%しおりに節番号などをつける
   colorlinks=false,%リンクには色をつけない
   hyperfootnotes=false,%脚注からのリンクを作らない
   pdfborder={0 0 0},%枠なし
   pdfpagemode=UseNone]{hyperref}
   

% PDFにしたときの文字化けを防ぐ
\usepackage{pxjahyper}

\title{パターン認識 -- 課題3}

\author{\large GENG Haopeng 611710008 \\ \small Email:  \href{mailto:kevingenghaopeng@gmail.com}{kevingenghaopeng@gmail.com}}
\affil{\small Department of Intelligent Systems, Nagoya University}

\date{\today}

\begin{document}
\maketitle

\begin{abstract}
今回の課題は、線形分離可能なパターンをパーセプトロンによるクラスタリングである。さらに、パーセプトロンの原理を理解した上で、実際問題を解決することである。
そのほか、課題のソースコードが既に\href{https://github.com/Secondtonumb/pattern_recogn/tree/master/pattern03}{Github Repository}に掲載されるため、参照あるいは実行することは可能である。
\end{abstract}


\section{パーセプトロンによる学習(基本編)}
\subsection{実験理論およびアルゴリズム}
この課題は、パーセプトロンの収束定理を利用し、重みベクトルを修正しつつ、線形分離可能なパターンであれば、解領域内の重みベクトルに到達する。いわゆる、全ての学習パターンが正しく識別される。
アルゴリズム\cite{教科書}の手順は以下のように表す：
\begin{itemize}
\small
\item[1] 重みベクトル$\bm{w}$の初期値を決める
\item[2] パターン集合$\mathcal{X}$から順番で一つのパターン$\omega_{i}$を選ぶ
\item[3] 識別関数
	$$g(\bm{x})=\bm{w}^{t}\bm{x}$$
	によって識別を行い。正しく識別できなかった場合、次のように重みベクトルを修正する。
	$$\bm{w}^{'}= \bm{w} +\rho\bm{x}    (\omega_{i}\in\mathcal{X},g_{i}(\bm{x})\neq \max\{g_{1}(\bm{x}),g_{2}(\bm{x}),\cdots,g_{n}(\bm{x}) \})$$
	$$\bm{w}^{'}= \bm{w} -\rho\bm{x}     (\omega_{j}\in\mathcal{X},g_{j}(\bm{x})= \max\{g_{1}(\bm{x}),g_{2}(\bm{x}),\cdots,g_{n}(\bm{x}) \})$$
\item[4] 上の処理[2], [3]全てのパターンに対して繰り返す
\item[5]  $\forall \omega_{i}\in\mathcal{X}$,正しく識別できたら終了、誤りがあるときは[2]に戻る
\end{itemize}

ただし、最大値が複数個出現する場合、計算順で最初に出た重みのみ修正する。

\subsection{プログラムに工夫した部分}
誤り識別するとき、重みベクトルの修正は以下順番で処理する。
\begin{itemize}
\small
\item[1] 全ての重みベクトルに対応する信号量を判断する、すべて「修正済み」になる場合、ステップ5へ
\item[2] 該当パターンにおいて、識別関数を計算する
\subitem2.1誤識別の場合、修正式による重みの修正
\subitem2.2正しい識別の場合、収束信号量を「修正済み」に設定
\item[3] 次のパターンを導入
\item[4] 全ての重みが修正終了
\end{itemize}

\begin{lstlisting}[language=c,caption=correct weight vector,]
 /* calculate until converge, while converge condition is all pattern have become stable */
  while(conv(flag, LEARNING_NUM)){
    if(p >= LEARNING_NUM) p = p % LEARNING_NUM;
    for(j = 0; j < CLU_NUM; j++){
      eval[j] = multi(p_arr[p].data, w[j], CLU_NUM);
        }
    /* Corr is pattern's true Class */
    /* Err is Evaluated Class, if condition is met , err == -1 */
    int corr = p_arr[p].pclass;
    int err = judge_max(eval, CLU_NUM, corr);
    printf("Right Class = %d,Error Class = %d\n",corr,err);
    if(err != -1){
      flag[p] = 1;
      for(j = 0; j < W_DIM; j++){
        w[corr][j] += rho * p_arr[p].data[j];
        w[err][j] -= rho * p_arr[p].data[j];
      }
    }
    /* Weight Condition is met, change flag to let result converge */
    else{
      flag[p] = 0;
    }
    printf("========\n");
    for(i = 0; i < CLU_NUM; i++){
      for(j = 0; j < W_DIM; j++){
        printf("%.0f ",w[i][j]);
      }
      printf("\n");
    }
    p++;
  }
\end{lstlisting}

\subsection{プログラム実行例}
\subsubsection{重みベクトルの修正}
与えられたパターンと初期重みを用い、以下のように出力される。ただし、20回の繰り返し演算を略し、結果のみを表す。
\begin{lstlisting}[language=bash]
$./pl learning_data.list init_weight.dat weight.dat
.
.
.
Evaluation of Pattern 1 by g(0) : 13.000000
Evaluation of Pattern 1 by g(1) : 9.000000
Evaluation of Pattern 1 by g(2) : 12.000000
Right Class = 0,Error Class = -1
========
9 2 0
2 1 5
-2 6 2
\end{lstlisting}

出力結果について、

\begin{itemize}
\item[1] 各評価関数の値
\item[2] 所属すべきクラス、識別関数による識別結果
\item[3] 修正された重みベクトル
\end{itemize}

という順番で示され、ゆえに、合計20回の修正で、学習結果である重みベクトルは
$\bm{W} = 
 \begin{bmatrix}
   9 & 2 & 0 \\
   2 & 1 & 5 \\
   -2 & 6 & 2
  \end{bmatrix}
$になった。

\subsubsection{未知パターン識別}
上記の重みベクトルを用い、未知パターンの識別を行った。
\begin{lstlisting}[language=bash]
$./pl_rec weight.dat unknown.dat
Value of g[0]: 13.000000
Value of g[1]: 14.000000
Value of g[2]: 14.000000
recog result == -1
\end{lstlisting}
実験結果から、識別関数の最大値が複数個（g[1], g[2]）あるため、識別できない結果になることがわかった。

\subsection{考察}
\subsubsection{初期ベクトルの変化による影響}
$\bm{W_{init}}$をランダムに500個を選び、識別結果を評価した結果は表１で示す。

\begin{table}[h]\small
\centering
\caption{500個の初期重みベクトルの実験結果($w_{ij}\in[-5, 5] , w_{ij} \in \bm{Z}$)}
\label{table}
\begin{tabular}{|l|c|c|c|c|} 
\hline  
識別結果 & ${w_{1}}$ & ${w_{2}}$ & ${w_{3}}$ & Unrec  \\
\hline
識別数 & 131 & 84 & 180 & 105 \\
\hline
比率 & 26.2\% & 16.8\% & 36.0\% & 21.0\%\\
\hline                       
\end{tabular} 
\end{table}

よって、正しい識別率は26.2\%になった。つまり、初期重みは識別結果に大きな影響を与え得ることがわかった。

\subsubsection{定数$\rho$の変化による影響}
定数$\rho$を0.1から1.5まで、刻み幅を0.1、および$\rho = 2.0, 3.0,4.0,5.0,6.0$に設定し実験した結果は表2のように表す。
\begin{table}[h]\small
\centering
\caption{$\rho$の変化による実験結果}
\label{table}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|} 
\hline  
$\rho$ & 識別結果 & $\rho$& 識別結果& $\rho$ & 識別結果& $\rho$ & 識別結果 &識別率\\
\hline
0.1 & ${\surd}$& 0.6 & ${\surd}$ & 1.1 & Err($w_{2}$)& 2.0& ${\surd}$&\multirow{5}*{75.0\%}\\
\cline{1-8}
0.2 & ${\surd}$& 0.7 & ${\surd}$ & 1.2 &  ${\surd}$ & 3.0& Unrec & \\
\cline{1-8}
0.3 & ${\surd}$& 0.8 & ${\surd}$& 1.3 &  ${\surd}$& 4.0& ${\surd}$ & \\
\cline{1-8}
0.4 & ${\surd}$& 0.9 & ${\surd}$& 1.4 &  ${\surd}$ & 5.0& ${\surd}$ &\\
\cline{1-8}
0.5 & Unrec & 1.0 & Unrec & 1.5 &  Unrec & 6.0& ${\surd}$ &\\
\hline                       
\end{tabular} 
\end{table}

実験結果により、$\rho = 0.5 ,1.0, 1.5, 3.0$の時、識別できない場合は多いことがわかり、初期重みとパターンの値は整数であるは原因であると考える。
なお、修正係数が大きくなったら識別結果が悪くなると想定したが、実験結果としてそれほど影響していないことがわかった。

\section{パーセプトロンによる学習(応用編)}
\subsection{実験目的}

上記の実験に基づき、日本各地の座標を学習パターンとし、パーセプトロンによる学習で地域の天気を予測することを実験した。
ただし、処理しやすいため、初期重みを一定範囲内にランダムに設定し、重み修正幅$\rho=1.0$と設定し、各クラスターを$ 晴れ=0,曇り=1,雨=2 $と設定する。

\subsection{プログラム実行例および実行結果}

pattern7-5.datを例として、以下のように出力される。

\begin{lstlisting}[language=bash]
$./pl weather.list wea_init_weight.dat weather_weight.dat 1
.
.
.
Evaluation of Pattern 2 by g(0) : 10.110000
Evaluation of Pattern 2 by g(1) : 18.690000
Evaluation of Pattern 2 by g(2) : -4.000000
Right Class = 1,Error Class = -1
========
0.000000 2.500000 8.700000
3.000000 5.000000 2.300000
2.000000 -1.500000 -5.000000

$./pl_rec weather_weight.dat unk_weather.dat
Value of g[0]: -5.480000
Value of g[1]: -1.920000
Value of g[2]: 5.200000
recog result == 2

\end{lstlisting}

出力結果について、得られた修正済みの重みベクトル
$\footnotesize
\bm{W} = 
 \begin{bmatrix}
   0.0 & 2.5 & 8.7 \\
   3.0 & 5.0 & 2.3 \\
   2.0 & -1.5 & -5.0
  \end{bmatrix}
$になり、識別関数の最大値は$g[2]$で、つまり、識別結果は雨という誤識別結果になる。
なお、$\rho$の識別値を0から2まで、刻み幅0.1で実験した結果、全ては誤識別であり、$\rho$の幅とはほぼ無関係であることがわかった。

\subsection{考察}

各学習パターンを観察した結果、晴れの学習パターンはほとんど第一象限に所存して、評価パターンは第3象限にあるため、学習パターンは不適切であると想定する。一つの改良法として、評価パターンの近くで新たに学習パターンを観測し、新学習パターンを含め重みベクトルの修正を行う。
パターンをそれぞれ学習パターンに加わり、識別結果を表3で表す。
\begin{table}[h]\small
\caption{追加パターンおよび識別結果}
\label{}
\centering
\begin{tabular}{|c|ccc|c|c|}
\hline
パターン名& x座標 & y座標 & 天気& 修正された重み& 識別結果\\
\hline
New1& - 0.9 & -0.5 & 晴れ&
$\footnotesize
\begin{bmatrix}
2.0&-3.6&10.8\\
2.0& 7.6& -5.3\\
-6.0& -5.0& -2.5\\
\end{bmatrix}
$
&晴れ\\
\hline
New2& - 0.7 & -0.3 & 晴れ &
$\footnotesize
 \begin{bmatrix}
1.0&-2.6&9.5&\\
1.0&3.0&-2.4&\\
-4.0&-1.4&-4.1&\\
 \end{bmatrix}
$
&曇り\\
\hline                                               
\end{tabular} 
\end{table}

よって、パターンNew1が正しく識別できるようになったが、New2が誤識別になった結果がわかった。


ゆえに、応用を通して、パーセプトロン法がクラスター分界線付近のパターンの識別力が低いという特徴がわかった。なお、観測データの選び方は識別結果に大きな影響を与え得ることがわかった。実際に応用する際、多層パーセプトロン、いわゆるニューラルネットワークによる識別する方が頼りになると考えられる。

\begin{thebibliography}{9}
    \bibitem{教科書} 石井健一郎, 上田修功, 村瀬洋, 等. わかりやすいパターン認識[M]. Ohmsha, 1998.
\end{thebibliography}

\end{document}